{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name\t: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# details of the processor\n",
    "!cat /proc/cpuinfo | grep -m 1 \"model name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Fast Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_gaussian(x, A, x0, w):\n",
    "    return A * np.exp(-(x - x0)**2. / (2. * w**2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10., 10., 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 ms ± 36.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit single_gaussian(x, 1., 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.48.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_single_gaussian = numba.jit(single_gaussian, nopython=True, fastmath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 µs ± 5.58 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jit_single_gaussian(x, 1., 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate multiple Gaussians now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_multiple_gaussians(x: np.ndarray, A: np.ndarray, x0: np.ndarray, w: np.ndarray):\n",
    "    Y = np.zeros((x.size, len(A)))\n",
    "    ngaussians = len(A)\n",
    "    # loop over each Gaussian\n",
    "    for i in range(ngaussians):\n",
    "        # Use the previously jit'd function to compute gaussians\n",
    "        Y[:,i] = jit_single_gaussian(x, A[i], x0[i], w[i])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngaussians = 100\n",
    "\n",
    "A = np.random.normal(5., 2., ngaussians)\n",
    "x0 = np.random.rand(ngaussians)\n",
    "w = abs(np.random.rand(ngaussians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit first_multiple_gaussians(x, A, x0, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_first_multiple_gaussians = numba.jit(first_multiple_gaussians, nopython=True, fastmath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412 ms ± 5.06 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jit_first_multiple_gaussians(x, A, x0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelize for loop\n",
    "\n",
    "A trivial way of improving the performance is by making the `for` loop parallelizable: we can do different parts of the loop asynchronously, instead of in a serial fashion. The `jit` functionality in Numba gives us the option to provide a kwarg, `parallel=True`, which will then automatically parallelize eligible parts of the code. In particular, we replace the Python `range` generator with `numba.prange`, which will parallelize the `for` loop.\n",
    "\n",
    "The rest of the code is identical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True, parallel=True, nogil=True)\n",
    "def second_multiple_gaussians(x: np.ndarray, A: np.ndarray, x0: np.ndarray, w: np.ndarray):\n",
    "    Y = np.zeros((x.size, len(A)))\n",
    "    ngaussians = len(A)\n",
    "    # Replace range generator with numba.prange to parallelize for loop\n",
    "    for i in numba.prange(ngaussians):\n",
    "        # Use the previously jit'd function to compute gaussians\n",
    "        Y[:,i] = jit_single_gaussian(x, A[i], x0[i], w[i])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 ms ± 6.44 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit second_multiple_gaussians(x, A, x0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Being more clever about vectorization\n",
    "\n",
    "In the previous implementations, we used a naive `for` loop to iterate over each of our Gaussians. By taking advantage of vectorization, however, we can potentially obtain a significant improvement in performance: in a `for` loop, NumPy will complete a computation and return back to Python between every iteration, whereas vectorization means handing off one big task to NumPy to complete without needing to go back to Python until it's done. The back and forth communication involved overhead, and definitely adds the bigger the loop.\n",
    "\n",
    "In the implementation below, we're going to use pure NumPy, without any JIT compilation. Instead of looping and computing the amplitude of each Gaussian per iteration, we're going to compute them all at once! To obtain our 2D array of values, we take the `x` array, reshape and repeat it so that every row corresponds to a Gaussian. We will then reshape the Gaussian parameters into 2D arrays with a single column; each row also corresponds to the parameters for a Gaussian. Taking advantage of element-wise broadcasting, we are effectively sweeping across `x`, and transforming each element into the corresponding Gaussian amplitude gradually.\n",
    "\n",
    "A big part of this is the ability to perform all the operations inplace: as you'll see in the code below, we take extra care to make sure there are no re-allocations of arrays, which will induce some overhead where NumPy will internally make copies of arrays if you're not careful. For example:\n",
    "\n",
    "```Y = np.square(Y)```\n",
    "\n",
    "will cause NumPy to make a copy of the array, even though logically (to us) we are taking the square of the array and setting it as itself. Core NumPy math functions have an `out` keyword which will dump the result into a pre-allocated array, so `Y = np.square(Y, out=Y)` will tell NumPy there is no need to make a copy of an array, just send the outputs back to `Y`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_multiple_gaussians(x: np.ndarray, A: np.ndarray, x0: np.ndarray, w: np.ndarray):\n",
    "    # get the expected number of Gaussians\n",
    "    ngaussians = len(A)\n",
    "    # first reshape the 1D x array into a one row 2D array, then\n",
    "    # repeat the row `ngaussian` number of times along rows\n",
    "    Y = np.repeat(x.reshape(1, -1), ngaussians, axis=0)\n",
    "    # reshape the parameters into a column vector, so that the number\n",
    "    # of rows match the number of Gaussians\n",
    "    A, x0, w = A.reshape(-1, 1), x0.reshape(-1, 1), w.reshape(-1, 1)\n",
    "    # start performing in-place operations, transforming the x values\n",
    "    # into the Gaussian amplitude corresponding to each row\n",
    "    Y -= x0\n",
    "    Y = np.square(Y, out=Y)\n",
    "    Y /= (2 * w**2)\n",
    "    Y = np.negative(Y, out=Y)\n",
    "    Y = np.exp(Y, out=Y)\n",
    "    Y *= A\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 ms ± 9.58 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit vectorized_multiple_gaussians(x, A, x0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectorized multiple Gaussian implementation gets us much closer to the parallelized Numba JIT'd version, even without compilation or optimizations! That means we could potentially beat the previous implementation if we add a touch of JIT! However, unfortunately it seems that the Numba analogs of NumPy functions do not support the `out` keywords, and so there may be some overhead. Another problem is that the array `repeat` function also does not supply an `axis` argument, and so we have to split the function into two, and only JIT the actual computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(fastmath=True, nogil=True, parallel=True)\n",
    "def jit_vec_multi_gaussian(Y: np.ndarray, A: np.ndarray, x0: np.ndarray, w: np.ndarray):\n",
    "    A, x0, w = A.reshape(-1, 1), x0.reshape(-1, 1), w.reshape(-1, 1)\n",
    "    Y -= x0\n",
    "    Y *= Y\n",
    "    Y /= (2 * w**2)\n",
    "    Y = np.negative(Y)\n",
    "    Y = np.exp(Y)\n",
    "    Y *= A\n",
    "    return Y\n",
    "\n",
    "def jit_vec_wrapper(x: np.ndarray, A: np.ndarray, x0: np.ndarray, w: np.ndarray):\n",
    "    ngaussians = len(A)\n",
    "    Y = np.repeat(x.reshape(1, -1), ngaussians, axis=0)\n",
    "    Y = jit_vec_multi_gaussian(Y, A, x0, w)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This halved our computation time! If you take the JIT flags out, you'll find that the biggest difference is provided by `parallel=True`: our arrays are big enough that parallelizing the computation on a single array provides more benefit than the overhead associated with parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 9.81 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jit_vec_wrapper(x, A, x0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Jax JIT compilation\n",
    "\n",
    "Jax is a relatively new library that provides a different kind of JIT compilation to Numba: instead of relying generating LLVM code, Jax uses XLA (a linear algebra optimization library). Since this type of optimization is more or less entirely orthogonal, we will get different kinds of speed ups here. One of the more notable ones is that `jp.repeat` supports an `axis` argument, meaning we can enclose the entire operation in a single function. The rest of the code is more or less the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.62'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jp\n",
    "\n",
    "jax.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_vectorized_multiple_gaussians(x: np.ndarray, A: np.ndarray, x0: np.ndarray, w: np.ndarray):\n",
    "    ngaussians = len(A)\n",
    "    Y = jp.repeat(x.reshape(1, -1), ngaussians, axis=0)\n",
    "    A, x0, w = A.reshape(-1, 1), x0.reshape(-1, 1), w.reshape(-1, 1)\n",
    "    Y -= x0\n",
    "    Y = jp.square(Y)\n",
    "    Y /= (2 * w**2)\n",
    "    Y = jp.exp(-Y)\n",
    "    Y *= A\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a JIT'd version of the function\n",
    "jax_jit_vec = jp.jit(jax_vectorized_multiple_gaussians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvin/anaconda3/envs/uml/lib/python3.7/site-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2 ms ± 596 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jax_jit_vec(x, A, x0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an order of magnitude faster! I'm not 100% sure what the XLA compilation is doing better than the Numba LLVM in this case, and so I would recommend trying both methods when needing to write code for speed and experimenting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 understanding-ml",
   "language": "python",
   "name": "uml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
